{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\", activation=\"elu\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('cifar10_model.m5', save_best_only=True)\n",
    "run_index = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tensorboard to compare lr for 10 epochs. I compared 1e-5,5e-5 and 3e-5. 3e-5 and 3e-5 were good. 5e-5 was best. Check logs for more details in the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"dnn_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 4.4372 - accuracy: 0.1514WARNING:tensorflow:From /Users/sidparmar/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 14s 317us/sample - loss: 4.4367 - accuracy: 0.1514 - val_loss: 2.1964 - val_accuracy: 0.1978\n",
      "Epoch 2/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 2.0672 - accuracy: 0.2350INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 266us/sample - loss: 2.0672 - accuracy: 0.2350 - val_loss: 1.9694 - val_accuracy: 0.2792\n",
      "Epoch 3/100\n",
      "44960/45000 [============================>.] - ETA: 0s - loss: 1.9502 - accuracy: 0.2818INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 264us/sample - loss: 1.9501 - accuracy: 0.2818 - val_loss: 1.9104 - val_accuracy: 0.2986\n",
      "Epoch 4/100\n",
      "44896/45000 [============================>.] - ETA: 0s - loss: 1.8817 - accuracy: 0.3115INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 262us/sample - loss: 1.8817 - accuracy: 0.3115 - val_loss: 1.8433 - val_accuracy: 0.3276\n",
      "Epoch 5/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 1.8238 - accuracy: 0.3369INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 263us/sample - loss: 1.8239 - accuracy: 0.3369 - val_loss: 1.7944 - val_accuracy: 0.3444\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.7751 - accuracy: 0.3571 - val_loss: 1.8000 - val_accuracy: 0.3472\n",
      "Epoch 7/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 1.7300 - accuracy: 0.3722INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 259us/sample - loss: 1.7299 - accuracy: 0.3723 - val_loss: 1.7440 - val_accuracy: 0.3718\n",
      "Epoch 8/100\n",
      "44768/45000 [============================>.] - ETA: 0s - loss: 1.6899 - accuracy: 0.3888INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 260us/sample - loss: 1.6900 - accuracy: 0.3886 - val_loss: 1.6947 - val_accuracy: 0.3896\n",
      "Epoch 9/100\n",
      "44896/45000 [============================>.] - ETA: 0s - loss: 1.6580 - accuracy: 0.3996INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 273us/sample - loss: 1.6579 - accuracy: 0.3996 - val_loss: 1.6601 - val_accuracy: 0.4012\n",
      "Epoch 10/100\n",
      "44928/45000 [============================>.] - ETA: 0s - loss: 1.6295 - accuracy: 0.4095INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 270us/sample - loss: 1.6296 - accuracy: 0.4095 - val_loss: 1.6476 - val_accuracy: 0.4002\n",
      "Epoch 11/100\n",
      "44864/45000 [============================>.] - ETA: 0s - loss: 1.6014 - accuracy: 0.4206INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 273us/sample - loss: 1.6013 - accuracy: 0.4207 - val_loss: 1.6345 - val_accuracy: 0.4120\n",
      "Epoch 12/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 1.5829 - accuracy: 0.4289INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 270us/sample - loss: 1.5830 - accuracy: 0.4289 - val_loss: 1.6078 - val_accuracy: 0.4216\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 12s 256us/sample - loss: 1.5595 - accuracy: 0.4383 - val_loss: 1.6342 - val_accuracy: 0.4106\n",
      "Epoch 14/100\n",
      "44928/45000 [============================>.] - ETA: 0s - loss: 1.5454 - accuracy: 0.4413INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 13s 289us/sample - loss: 1.5451 - accuracy: 0.4413 - val_loss: 1.5889 - val_accuracy: 0.4294\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 10s 226us/sample - loss: 1.5225 - accuracy: 0.4512 - val_loss: 1.5988 - val_accuracy: 0.4294\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 10s 227us/sample - loss: 1.5065 - accuracy: 0.4555 - val_loss: 1.5928 - val_accuracy: 0.4356\n",
      "Epoch 17/100\n",
      "44960/45000 [============================>.] - ETA: 0s - loss: 1.4943 - accuracy: 0.4617INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 275us/sample - loss: 1.4944 - accuracy: 0.4616 - val_loss: 1.5708 - val_accuracy: 0.4244\n",
      "Epoch 18/100\n",
      "44896/45000 [============================>.] - ETA: 0s - loss: 1.4779 - accuracy: 0.4673INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 267us/sample - loss: 1.4781 - accuracy: 0.4673 - val_loss: 1.5598 - val_accuracy: 0.4456\n",
      "Epoch 19/100\n",
      "44800/45000 [============================>.] - ETA: 0s - loss: 1.4638 - accuracy: 0.4715INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 270us/sample - loss: 1.4639 - accuracy: 0.4715 - val_loss: 1.5529 - val_accuracy: 0.4450\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 10s 226us/sample - loss: 1.4523 - accuracy: 0.4748 - val_loss: 1.5934 - val_accuracy: 0.4262\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 10s 227us/sample - loss: 1.4395 - accuracy: 0.4832 - val_loss: 1.5736 - val_accuracy: 0.4358\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 10s 233us/sample - loss: 1.4269 - accuracy: 0.4868 - val_loss: 1.5663 - val_accuracy: 0.4384\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 10s 233us/sample - loss: 1.4150 - accuracy: 0.4918 - val_loss: 1.5768 - val_accuracy: 0.4362\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 10s 233us/sample - loss: 1.4005 - accuracy: 0.4964 - val_loss: 1.5640 - val_accuracy: 0.4378\n",
      "Epoch 25/100\n",
      "44832/45000 [============================>.] - ETA: 0s - loss: 1.3960 - accuracy: 0.4999INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 276us/sample - loss: 1.3964 - accuracy: 0.4998 - val_loss: 1.5445 - val_accuracy: 0.4450\n",
      "Epoch 26/100\n",
      "44768/45000 [============================>.] - ETA: 0s - loss: 1.3833 - accuracy: 0.5022INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 265us/sample - loss: 1.3829 - accuracy: 0.5024 - val_loss: 1.5326 - val_accuracy: 0.4580\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 10s 230us/sample - loss: 1.3756 - accuracy: 0.5095 - val_loss: 1.5825 - val_accuracy: 0.4344\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 10s 229us/sample - loss: 1.3631 - accuracy: 0.5125 - val_loss: 1.5766 - val_accuracy: 0.4434\n",
      "Epoch 29/100\n",
      "44992/45000 [============================>.] - ETA: 0s - loss: 1.3561 - accuracy: 0.5139INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 272us/sample - loss: 1.3561 - accuracy: 0.5139 - val_loss: 1.5242 - val_accuracy: 0.4540\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 10s 233us/sample - loss: 1.3494 - accuracy: 0.5156 - val_loss: 1.5279 - val_accuracy: 0.4480\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 1.3358 - accuracy: 0.5183 - val_loss: 1.5465 - val_accuracy: 0.4518\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 1.3271 - accuracy: 0.5246 - val_loss: 1.5328 - val_accuracy: 0.4596\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.3184 - accuracy: 0.5255 - val_loss: 1.5310 - val_accuracy: 0.4630\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44832/45000 [============================>.] - ETA: 0s - loss: 1.3097 - accuracy: 0.5286INFO:tensorflow:Assets written to: cifar10_model.m5/assets\n",
      "45000/45000 [==============================] - 12s 277us/sample - loss: 1.3098 - accuracy: 0.5284 - val_loss: 1.5216 - val_accuracy: 0.4604\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.3020 - accuracy: 0.5313 - val_loss: 1.5783 - val_accuracy: 0.4522\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.2906 - accuracy: 0.5361 - val_loss: 1.5372 - val_accuracy: 0.4604\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.2850 - accuracy: 0.5399 - val_loss: 1.5591 - val_accuracy: 0.4494\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 11s 253us/sample - loss: 1.2780 - accuracy: 0.5416 - val_loss: 1.5310 - val_accuracy: 0.4666\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 12s 256us/sample - loss: 1.2655 - accuracy: 0.5457 - val_loss: 1.5724 - val_accuracy: 0.4546\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 12s 263us/sample - loss: 1.2600 - accuracy: 0.5465 - val_loss: 1.5930 - val_accuracy: 0.4516\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 11s 250us/sample - loss: 1.2528 - accuracy: 0.5482 - val_loss: 1.5382 - val_accuracy: 0.4606\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 11s 247us/sample - loss: 1.2414 - accuracy: 0.5543 - val_loss: 1.5249 - val_accuracy: 0.4558\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 11s 241us/sample - loss: 1.2355 - accuracy: 0.5561 - val_loss: 1.5408 - val_accuracy: 0.4488\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 1.2239 - accuracy: 0.5611 - val_loss: 1.5444 - val_accuracy: 0.4584\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 1.2188 - accuracy: 0.5630 - val_loss: 1.5348 - val_accuracy: 0.4618\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 1.2102 - accuracy: 0.5654 - val_loss: 1.5464 - val_accuracy: 0.4592\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.2049 - accuracy: 0.5676 - val_loss: 1.6094 - val_accuracy: 0.4550\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 11s 236us/sample - loss: 1.1978 - accuracy: 0.5704 - val_loss: 1.5802 - val_accuracy: 0.4564\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 10s 230us/sample - loss: 1.1925 - accuracy: 0.5714 - val_loss: 1.5961 - val_accuracy: 0.4466\n",
      "Epoch 50/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.1845 - accuracy: 0.5744 - val_loss: 1.6236 - val_accuracy: 0.4444\n",
      "Epoch 51/100\n",
      "45000/45000 [==============================] - 10s 230us/sample - loss: 1.1768 - accuracy: 0.5788 - val_loss: 1.5967 - val_accuracy: 0.4536\n",
      "Epoch 52/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.1671 - accuracy: 0.5799 - val_loss: 1.5912 - val_accuracy: 0.4558\n",
      "Epoch 53/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.1597 - accuracy: 0.5835 - val_loss: 1.5947 - val_accuracy: 0.4540\n",
      "Epoch 54/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 1.1579 - accuracy: 0.5838 - val_loss: 1.5788 - val_accuracy: 0.4608\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only got 47.90% val_accuracy after 50 epochs (early stopping).\n",
    "\n",
    "\n",
    "Now let's try using Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "model.add(keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_bn_model.h5\", save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "import time\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_bn_logs\", time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 23s 515us/sample - loss: 1.8323 - accuracy: 0.3463 - val_loss: 1.6298 - val_accuracy: 0.4128\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 17s 371us/sample - loss: 1.6608 - accuracy: 0.4088 - val_loss: 1.5896 - val_accuracy: 0.4336\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 17s 376us/sample - loss: 1.5975 - accuracy: 0.4310 - val_loss: 1.5215 - val_accuracy: 0.4560\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 17s 377us/sample - loss: 1.5411 - accuracy: 0.4543 - val_loss: 1.4518 - val_accuracy: 0.4736\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 17s 379us/sample - loss: 1.5006 - accuracy: 0.4691 - val_loss: 1.4334 - val_accuracy: 0.4844\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 17s 381us/sample - loss: 1.4608 - accuracy: 0.4811 - val_loss: 1.4392 - val_accuracy: 0.4904\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 17s 376us/sample - loss: 1.4324 - accuracy: 0.4927 - val_loss: 1.4149 - val_accuracy: 0.4872\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 17s 379us/sample - loss: 1.4052 - accuracy: 0.5027 - val_loss: 1.3970 - val_accuracy: 0.5044\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 16s 364us/sample - loss: 1.3751 - accuracy: 0.5160 - val_loss: 1.4050 - val_accuracy: 0.5122\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 17s 380us/sample - loss: 1.3506 - accuracy: 0.5234 - val_loss: 1.3739 - val_accuracy: 0.5098\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 17s 381us/sample - loss: 1.3332 - accuracy: 0.5287 - val_loss: 1.3643 - val_accuracy: 0.5244\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 16s 364us/sample - loss: 1.3102 - accuracy: 0.5354 - val_loss: 1.3855 - val_accuracy: 0.5134\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 17s 378us/sample - loss: 1.2957 - accuracy: 0.5429 - val_loss: 1.3560 - val_accuracy: 0.5254\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 17s 375us/sample - loss: 1.2744 - accuracy: 0.5482 - val_loss: 1.3514 - val_accuracy: 0.5286\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 17s 376us/sample - loss: 1.2604 - accuracy: 0.5536 - val_loss: 1.3967 - val_accuracy: 0.5060\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 17s 371us/sample - loss: 1.2442 - accuracy: 0.5589 - val_loss: 1.3894 - val_accuracy: 0.5228\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 17s 377us/sample - loss: 1.2273 - accuracy: 0.5666 - val_loss: 1.3232 - val_accuracy: 0.5372\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 16s 364us/sample - loss: 1.2139 - accuracy: 0.5711 - val_loss: 1.3328 - val_accuracy: 0.5408\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 18s 398us/sample - loss: 1.1937 - accuracy: 0.5756 - val_loss: 1.3381 - val_accuracy: 0.5410\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 19s 430us/sample - loss: 1.1856 - accuracy: 0.5847 - val_loss: 1.3374 - val_accuracy: 0.5278\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 18s 396us/sample - loss: 1.1749 - accuracy: 0.5862 - val_loss: 1.3479 - val_accuracy: 0.5384\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 17s 373us/sample - loss: 1.1611 - accuracy: 0.5896 - val_loss: 1.3282 - val_accuracy: 0.5506\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 17s 369us/sample - loss: 1.1487 - accuracy: 0.5947 - val_loss: 1.3283 - val_accuracy: 0.5336\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 17s 372us/sample - loss: 1.1315 - accuracy: 0.5970 - val_loss: 1.3275 - val_accuracy: 0.5344\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 17s 383us/sample - loss: 1.1214 - accuracy: 0.6053 - val_loss: 1.3245 - val_accuracy: 0.5406\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 17s 383us/sample - loss: 1.1099 - accuracy: 0.6089 - val_loss: 1.3384 - val_accuracy: 0.5334\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 17s 376us/sample - loss: 1.0954 - accuracy: 0.6116 - val_loss: 1.3447 - val_accuracy: 0.5346\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 18s 405us/sample - loss: 1.0839 - accuracy: 0.6188 - val_loss: 1.3630 - val_accuracy: 0.5398\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 19s 427us/sample - loss: 1.0768 - accuracy: 0.6205 - val_loss: 1.3195 - val_accuracy: 0.5414\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 17s 383us/sample - loss: 1.0650 - accuracy: 0.6237 - val_loss: 1.3524 - val_accuracy: 0.5392\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 17s 378us/sample - loss: 1.0549 - accuracy: 0.6270 - val_loss: 1.3441 - val_accuracy: 0.5410\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 17s 378us/sample - loss: 1.0421 - accuracy: 0.6326 - val_loss: 1.3701 - val_accuracy: 0.5354\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 17s 372us/sample - loss: 1.0357 - accuracy: 0.6335 - val_loss: 1.3624 - val_accuracy: 0.5366\n",
      "Epoch 34/100\n",
      "45000/45000 [==============================] - 17s 380us/sample - loss: 1.0218 - accuracy: 0.6377 - val_loss: 1.3547 - val_accuracy: 0.5406\n",
      "Epoch 35/100\n",
      "45000/45000 [==============================] - 17s 380us/sample - loss: 1.0200 - accuracy: 0.6392 - val_loss: 1.3730 - val_accuracy: 0.5294\n",
      "Epoch 36/100\n",
      "45000/45000 [==============================] - 17s 387us/sample - loss: 1.0070 - accuracy: 0.6443 - val_loss: 1.3474 - val_accuracy: 0.5440\n",
      "Epoch 37/100\n",
      "45000/45000 [==============================] - 20s 437us/sample - loss: 0.9971 - accuracy: 0.6478 - val_loss: 1.3534 - val_accuracy: 0.5480\n",
      "Epoch 38/100\n",
      "45000/45000 [==============================] - 18s 398us/sample - loss: 0.9882 - accuracy: 0.6505 - val_loss: 1.3815 - val_accuracy: 0.5324\n",
      "Epoch 39/100\n",
      "45000/45000 [==============================] - 16s 361us/sample - loss: 0.9811 - accuracy: 0.6533 - val_loss: 1.3764 - val_accuracy: 0.5402\n",
      "Epoch 40/100\n",
      "45000/45000 [==============================] - 16s 362us/sample - loss: 0.9703 - accuracy: 0.6571 - val_loss: 1.3777 - val_accuracy: 0.5396\n",
      "Epoch 41/100\n",
      "45000/45000 [==============================] - 17s 371us/sample - loss: 0.9629 - accuracy: 0.6598 - val_loss: 1.3997 - val_accuracy: 0.5376\n",
      "Epoch 42/100\n",
      "45000/45000 [==============================] - 18s 395us/sample - loss: 0.9553 - accuracy: 0.6631 - val_loss: 1.3941 - val_accuracy: 0.5452\n",
      "Epoch 43/100\n",
      "45000/45000 [==============================] - 19s 416us/sample - loss: 0.9430 - accuracy: 0.6677 - val_loss: 1.3797 - val_accuracy: 0.5400\n",
      "Epoch 44/100\n",
      "45000/45000 [==============================] - 17s 385us/sample - loss: 0.9321 - accuracy: 0.6720 - val_loss: 1.3901 - val_accuracy: 0.5338\n",
      "Epoch 45/100\n",
      "45000/45000 [==============================] - 18s 393us/sample - loss: 0.9281 - accuracy: 0.6732 - val_loss: 1.4232 - val_accuracy: 0.5334\n",
      "Epoch 46/100\n",
      "45000/45000 [==============================] - 17s 386us/sample - loss: 0.9212 - accuracy: 0.6754 - val_loss: 1.3825 - val_accuracy: 0.5442\n",
      "Epoch 47/100\n",
      "45000/45000 [==============================] - 17s 383us/sample - loss: 0.9103 - accuracy: 0.6765 - val_loss: 1.4033 - val_accuracy: 0.5454\n",
      "Epoch 48/100\n",
      "45000/45000 [==============================] - 17s 385us/sample - loss: 0.9059 - accuracy: 0.6789 - val_loss: 1.4241 - val_accuracy: 0.5340\n",
      "Epoch 49/100\n",
      "45000/45000 [==============================] - 19s 419us/sample - loss: 0.8996 - accuracy: 0.6831 - val_loss: 1.4230 - val_accuracy: 0.5396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 145us/sample - loss: 1.3195 - accuracy: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3195075395584106, 0.5414]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 49 epochs (early stopping) we have val_accuracy of 54.14%. Much better with BN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 12s 278us/sample - loss: 1.9205 - accuracy: 0.3098 - val_loss: 1.8802 - val_accuracy: 0.3310\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 1.7031 - accuracy: 0.3937 - val_loss: 1.7479 - val_accuracy: 0.3730\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.6103 - accuracy: 0.4280 - val_loss: 1.6813 - val_accuracy: 0.4164\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.5459 - accuracy: 0.4551 - val_loss: 1.5964 - val_accuracy: 0.4374\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 1.4882 - accuracy: 0.4763 - val_loss: 1.5311 - val_accuracy: 0.4632\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 1.4437 - accuracy: 0.4939 - val_loss: 1.5500 - val_accuracy: 0.4566\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.3995 - accuracy: 0.5101 - val_loss: 1.5092 - val_accuracy: 0.4702\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.3500 - accuracy: 0.5283 - val_loss: 1.5350 - val_accuracy: 0.4812\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.3278 - accuracy: 0.5364 - val_loss: 1.5373 - val_accuracy: 0.4766\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 12s 268us/sample - loss: 1.2947 - accuracy: 0.5486 - val_loss: 1.4661 - val_accuracy: 0.4918\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 14s 317us/sample - loss: 1.2645 - accuracy: 0.5596 - val_loss: 1.5427 - val_accuracy: 0.4676\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 14s 306us/sample - loss: 1.2334 - accuracy: 0.5742 - val_loss: 1.5317 - val_accuracy: 0.4788\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 12s 273us/sample - loss: 1.2043 - accuracy: 0.5841 - val_loss: 1.4621 - val_accuracy: 0.5054\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 11s 250us/sample - loss: 1.1823 - accuracy: 0.5938 - val_loss: 1.4993 - val_accuracy: 0.4864\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 11s 250us/sample - loss: 1.1626 - accuracy: 0.5983 - val_loss: 1.5113 - val_accuracy: 0.4952\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 11s 243us/sample - loss: 1.1410 - accuracy: 0.6083 - val_loss: 1.4873 - val_accuracy: 0.4982\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 11s 244us/sample - loss: 1.1133 - accuracy: 0.6200 - val_loss: 1.5460 - val_accuracy: 0.5006\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 11s 252us/sample - loss: 1.0980 - accuracy: 0.6239 - val_loss: 1.4991 - val_accuracy: 0.5074\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 12s 259us/sample - loss: 1.0719 - accuracy: 0.6321 - val_loss: 1.5663 - val_accuracy: 0.5168\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 11s 255us/sample - loss: 1.0618 - accuracy: 0.6370 - val_loss: 1.5024 - val_accuracy: 0.5108\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 11s 245us/sample - loss: 1.0440 - accuracy: 0.6432 - val_loss: 1.5497 - val_accuracy: 0.5036\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 11s 244us/sample - loss: 1.0219 - accuracy: 0.6520 - val_loss: 1.5375 - val_accuracy: 0.5028\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 11s 245us/sample - loss: 1.0048 - accuracy: 0.6567 - val_loss: 1.5206 - val_accuracy: 0.5044\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 11s 245us/sample - loss: 0.9852 - accuracy: 0.6685 - val_loss: 1.5335 - val_accuracy: 0.5122\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 11s 245us/sample - loss: 0.9720 - accuracy: 0.6720 - val_loss: 1.6100 - val_accuracy: 0.4920\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 11s 249us/sample - loss: 0.9571 - accuracy: 0.6750 - val_loss: 1.6076 - val_accuracy: 0.5010\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 11s 248us/sample - loss: 0.9405 - accuracy: 0.6808 - val_loss: 1.6290 - val_accuracy: 0.4960\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 11s 239us/sample - loss: 0.9260 - accuracy: 0.6874 - val_loss: 1.5810 - val_accuracy: 0.5046\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 11s 240us/sample - loss: 0.9175 - accuracy: 0.6909 - val_loss: 1.6635 - val_accuracy: 0.5142\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 11s 242us/sample - loss: 0.9134 - accuracy: 0.6911 - val_loss: 1.6273 - val_accuracy: 0.5020\n",
      "Epoch 31/100\n",
      "45000/45000 [==============================] - 11s 249us/sample - loss: 0.8777 - accuracy: 0.7049 - val_loss: 1.6651 - val_accuracy: 0.5044\n",
      "Epoch 32/100\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 192.9251 - accuracy: 0.6039 - val_loss: 1.5868 - val_accuracy: 0.4766\n",
      "Epoch 33/100\n",
      "45000/45000 [==============================] - 11s 252us/sample - loss: 1.0904 - accuracy: 0.6268 - val_loss: 1.5448 - val_accuracy: 0.4962\n",
      "5000/5000 [==============================] - 0s 79us/sample - loss: 1.4621 - accuracy: 0.5054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4621454309463502, 0.5054]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, \n",
    "                                 kernel_initializer=\"lecun_normal\", \n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_selu_model.h5\", save_best_only=True)\n",
    "import time\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_selu_logs\", time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100, \n",
    "         validation_data=(X_valid_scaled, y_valid),\n",
    "         callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 50.54% accuracy in 33 epochs. Also, notice that it took 19 epochs to reach the best model, which is much faster than bn model, plus each epoch took only 10 seconds, just like the original model. So it's by far the fastest model to train (both in terms of epochs and wall time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 13s 290us/sample - loss: 1.8904 - accuracy: 0.3267 - val_loss: 1.7513 - val_accuracy: 0.3918\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 10s 229us/sample - loss: 1.6593 - accuracy: 0.4117 - val_loss: 1.7569 - val_accuracy: 0.4128\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 11s 235us/sample - loss: 1.5673 - accuracy: 0.4478 - val_loss: 1.6128 - val_accuracy: 0.4516\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 1.5023 - accuracy: 0.4714 - val_loss: 1.6298 - val_accuracy: 0.4458\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.4484 - accuracy: 0.4913 - val_loss: 1.5310 - val_accuracy: 0.4768\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 1.4027 - accuracy: 0.5105 - val_loss: 1.5432 - val_accuracy: 0.4676\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 11s 233us/sample - loss: 1.3609 - accuracy: 0.5230 - val_loss: 1.5231 - val_accuracy: 0.4832\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 1.3212 - accuracy: 0.5375 - val_loss: 1.5610 - val_accuracy: 0.4960\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 10s 233us/sample - loss: 1.2883 - accuracy: 0.5506 - val_loss: 1.5443 - val_accuracy: 0.4976\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 11s 236us/sample - loss: 1.2569 - accuracy: 0.5657 - val_loss: 1.5090 - val_accuracy: 0.5032\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 11s 235us/sample - loss: 1.2222 - accuracy: 0.5782 - val_loss: 1.5650 - val_accuracy: 0.5064\n",
      "Epoch 12/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.1938 - accuracy: 0.5886 - val_loss: 1.5787 - val_accuracy: 0.5050\n",
      "Epoch 13/100\n",
      "45000/45000 [==============================] - 11s 235us/sample - loss: 1.1612 - accuracy: 0.6017 - val_loss: 1.5340 - val_accuracy: 0.5178\n",
      "Epoch 14/100\n",
      "45000/45000 [==============================] - 11s 235us/sample - loss: 1.1366 - accuracy: 0.6102 - val_loss: 1.5880 - val_accuracy: 0.5040\n",
      "Epoch 15/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 1.1143 - accuracy: 0.6171 - val_loss: 1.6582 - val_accuracy: 0.5054\n",
      "Epoch 16/100\n",
      "45000/45000 [==============================] - 11s 237us/sample - loss: 1.0868 - accuracy: 0.6263 - val_loss: 1.6001 - val_accuracy: 0.5124\n",
      "Epoch 17/100\n",
      "45000/45000 [==============================] - 11s 249us/sample - loss: 1.0648 - accuracy: 0.6383 - val_loss: 1.5882 - val_accuracy: 0.5088\n",
      "Epoch 18/100\n",
      "45000/45000 [==============================] - 11s 254us/sample - loss: 1.0368 - accuracy: 0.6453 - val_loss: 1.6263 - val_accuracy: 0.5152\n",
      "Epoch 19/100\n",
      "45000/45000 [==============================] - 11s 250us/sample - loss: 1.0199 - accuracy: 0.6536 - val_loss: 1.6012 - val_accuracy: 0.5134\n",
      "Epoch 20/100\n",
      "45000/45000 [==============================] - 12s 271us/sample - loss: 0.9937 - accuracy: 0.6619 - val_loss: 1.6911 - val_accuracy: 0.5124\n",
      "Epoch 21/100\n",
      "45000/45000 [==============================] - 12s 277us/sample - loss: 0.9820 - accuracy: 0.6667 - val_loss: 1.6761 - val_accuracy: 0.5142\n",
      "Epoch 22/100\n",
      "45000/45000 [==============================] - 11s 247us/sample - loss: 0.9621 - accuracy: 0.6739 - val_loss: 1.7736 - val_accuracy: 0.5078\n",
      "Epoch 23/100\n",
      "45000/45000 [==============================] - 10s 230us/sample - loss: 0.9455 - accuracy: 0.6788 - val_loss: 1.7841 - val_accuracy: 0.5106\n",
      "Epoch 24/100\n",
      "45000/45000 [==============================] - 10s 231us/sample - loss: 0.9269 - accuracy: 0.6870 - val_loss: 1.7648 - val_accuracy: 0.5026\n",
      "Epoch 25/100\n",
      "45000/45000 [==============================] - 10s 232us/sample - loss: 0.9062 - accuracy: 0.6948 - val_loss: 1.7912 - val_accuracy: 0.4958\n",
      "Epoch 26/100\n",
      "45000/45000 [==============================] - 11s 234us/sample - loss: 0.8951 - accuracy: 0.6977 - val_loss: 1.8090 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "45000/45000 [==============================] - 11s 238us/sample - loss: 0.8793 - accuracy: 0.7024 - val_loss: 1.8085 - val_accuracy: 0.5054\n",
      "Epoch 28/100\n",
      "45000/45000 [==============================] - 11s 243us/sample - loss: 0.8627 - accuracy: 0.7085 - val_loss: 1.7610 - val_accuracy: 0.5118\n",
      "Epoch 29/100\n",
      "45000/45000 [==============================] - 11s 246us/sample - loss: 0.8490 - accuracy: 0.7146 - val_loss: 1.8352 - val_accuracy: 0.4990\n",
      "Epoch 30/100\n",
      "45000/45000 [==============================] - 11s 241us/sample - loss: 0.8412 - accuracy: 0.7173 - val_loss: 1.9350 - val_accuracy: 0.5098\n",
      "5000/5000 [==============================] - 0s 75us/sample - loss: 1.5090 - accuracy: 0.5032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.509048455619812, 0.5032]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "import time\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_alpha_dropout_logs\", time.strftime(\"run_%Y_%m_%d-%H_%M_%S\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With alph dropout, we get 50.32% accuracy. Which is slightly less than what we got without dropout.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
